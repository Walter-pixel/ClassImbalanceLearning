{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b132247d-6f04-5a90-1eec-7f0872a70a98"
   },
   "source": [
    "## Hi all as we know credit card fraud detection will have a imbalanced data i.e having more number of normal class than the number of fraud class\n",
    "\n",
    "### In this I will use Basic method of handling imbalance data which are\n",
    " ** This all I have done by using Analytics Vidya's blog please find the link [Analytics Vidya](https://www.analyticsvidhya.com/blog/2017/03/read-commonly-used-formats-using-python/)  **\n",
    "\n",
    "Undersampling:- it means taking the less number of majority class (In our case taking less number of Normal transactions so that our new data will be balanced\n",
    "\n",
    "Oversampling: it means using replicating the data of minority class (fraud class) so that we can have a balanced data\n",
    "\n",
    "SMOTE: it is also a type of oversampling but in this we will make the synthetic example of Minority data and will give as a balanced data\n",
    "\n",
    "First I will start with the Undersampling and will try to classify using these Models\n",
    "\n",
    "1. Decision Tree Classifier/ Random Forest Classifier\n",
    "\n",
    "2. Logistic regression\n",
    "\n",
    "3. SVM\n",
    "\n",
    "4. XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "73c46801-7f23-67a2-47e8-03256085f659",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "7acc51d2-e9db-908f-9b91-386e23629483",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leshare/softwares/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # to import csv and for data manipulation\n",
    "import matplotlib.pyplot as plt # to plot graph\n",
    "import numpy as np # for linear algebra\n",
    "import datetime # to dela with date and time\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler # for preprocessing the data\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # for Decision Tree classifier\n",
    "from sklearn.svm import LinearSVC as SVC # for SVM classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split # to split the data\n",
    "from sklearn.cross_validation import KFold # For cross vbalidation\n",
    "from sklearn.model_selection import GridSearchCV # for tunnig hyper parameter it will use all combination of given parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV # same for tunning hyper parameter but will use random combinations of parameters\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "83f83459-d9f6-e2fd-9d11-77ee19a48ff0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/real/creditcard.csv\",header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "8c79df42-9432-e39e-cb27-6c53245f9ac5",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('percentage of normal transacation is', 99.82725143693798)\n",
      "('percentage of fraud transacation', 0.1727485630620034)\n"
     ]
    }
   ],
   "source": [
    "# now let us check in the number of Percentage\n",
    "Count_Normal_transacation = len(data[data[\"Class\"]==0]) # normal transaction are repersented by 0\n",
    "Count_Fraud_transacation = len(data[data[\"Class\"]==1]) # fraud by 1\n",
    "Percentage_of_Normal_transacation = 1.*Count_Normal_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of normal transacation is\",Percentage_of_Normal_transacation*100)\n",
    "Percentage_of_Fraud_transacation= 1.*Count_Fraud_transacation/(Count_Normal_transacation+Count_Fraud_transacation)\n",
    "print(\"percentage of fraud transacation\",Percentage_of_Fraud_transacation*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6bdeb418-1ad4-4101-a97f-218cad9d60b7"
   },
   "source": [
    "1. Hence in data there is only 0.17 % are the fraud transcation while 99.83 are valid transcation\n",
    "2. So now we have to do resampling of this data\n",
    "3. before doing resampling lets have look at the amount related to valid transcation and fraud transcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e7c06498-d474-1e15-ef69-7ead60df63c6"
   },
   "source": [
    "### No-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "12f3b2ed-4231-cddc-9959-d13491af2497",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now let us a define a function for make undersample data with different proportion\n",
    "#different proportion means with different proportion of normal classes of data\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def evaluate_auc_prc(y, pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y, pred)\n",
    "    aucprc = auc(recall, precision)\n",
    "    #print 'AUPRC:{}'.format(aucprc)\n",
    "    #plt.title('Precision Recall Curve')\n",
    "    #plt.plot(precision, recall, 'b',label='AUC = %0.2f'% aucprc)\n",
    "    #plt.legend(loc='lower right')\n",
    "    #plt.ylabel('Precision')\n",
    "    #plt.xlabel('Recall')\n",
    "    #plt.show()\n",
    "    return aucprc\n",
    "\n",
    "aucprc_scorer = make_scorer(evaluate_auc_prc, greater_is_better=True)\n",
    "\n",
    "def evaluate_f1(y, y_pred, pos_label=1):\n",
    "    f1 = f1_score(y, y_pred, pos_label=1)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print('precision:{} recall:{} F1: {}'.format(precision, recall, f1))\n",
    "\n",
    "def data_split(x, test_size=0.4, seed=1): # preparing data for training and testing as we are going to use different data \n",
    "    #again and again so make a function\n",
    "    x_features= x.ix[:,x.columns != \"Class\"]\n",
    "    x_labels=x.ix[:,x.columns==\"Class\"]\n",
    "    x_features_train,x_features_test,x_labels_train,x_labels_test = train_test_split(x_features,x_labels,\n",
    "                                                                                     test_size=test_size, \n",
    "                                                                                     random_state=seed)\n",
    "    x_features_train.index = np.arange(len(x_features_train))\n",
    "    x_labels_train.index = np.arange(len(x_labels_train))\n",
    "    x_features_test.index = np.arange(len(x_features_test))\n",
    "    x_labels_test.index = np.arange(len(x_labels_test))\n",
    "    print(\"length of training data\")\n",
    "    print(len(x_features_train))\n",
    "    print(\"length of test data\")\n",
    "    print(len(x_features_test))\n",
    "    return(x_features_train,x_features_test,x_labels_train,x_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8c5529ce-71ca-b24b-b544-e3d1443115f9",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# before starting we should standridze our amount column\n",
    "data[\"Normalized Amount\"] = StandardScaler().fit_transform(data['Amount'].reshape(-1, 1))\n",
    "data.drop([\"Time\",\"Amount\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:284807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "x_train = data.ix[:,data.columns != \"Class\"].values\n",
    "y_train = data.ix[:,data.columns==\"Class\"].values[:, 0]\n",
    "print 'train data size:{}'.format(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump({'x':x_train, 'y':np.eye(2)[y_train.astype('int32')]}, open('../data/real/creditcard/train.pkl', 'wb+'))\n",
    "idxes = np.arange(len(x_train))\n",
    "np.random.seed(1234)\n",
    "np.random.shuffle(idxes)\n",
    "x_train = x_train[idxes]\n",
    "y_train = y_train[idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import LinearSVC as SVM\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c for MLP:6\n",
      "best_reward MLP:0.823118981313\n"
     ]
    }
   ],
   "source": [
    "# Choose classifer with cross validation\n",
    "# Supervised Model: LR, SVM (linear), SVM (rbf), DT, KNN, MLP\n",
    "# Dataset: original\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# LR\n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]:\n",
    "#     clf = LR(C=c, random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=aucprc_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for LR:{}'.format(best_c)\n",
    "# print 'best_reward for LR:{}'.format(best_reward)\n",
    "\n",
    "# SVM (linear)\n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]:\n",
    "#     clf = SVM(C=c, random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=aucprc_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for SVM:{}'.format(best_c)\n",
    "# print 'best_reward for SVM:{}'.format(best_reward)\n",
    "\n",
    "# SVM (rbf)\n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]:\n",
    "#     clf = SVC(C=c, kernel='rbf', random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=aucprc_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for SVC:{}'.format(best_c)\n",
    "# print 'best_reward for SVC:{}'.format(best_reward)\n",
    "\n",
    "# DT \n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "#     clf = DT(max_depth=c, random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=aucprc_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for DT:{}'.format(best_c)\n",
    "# print 'best_reward DT:{}'.format(best_reward)\n",
    "\n",
    "# KNN \n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "#     clf = KNN(n_neighbors=c)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=aucprc_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for KNN:{}'.format(best_c)\n",
    "# print 'best_reward KNN:{}'.format(best_reward)\n",
    "\n",
    "# MLP \n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "    clf = MLP(hidden_layer_sizes=[5, c], random_state=0)\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=aucprc_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c for MLP:{}'.format(best_c)\n",
    "print 'best_reward MLP:{}'.format(best_reward)\n",
    "# 0.82582, c=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c:1.0\n",
      "best_reward:0.806395661911\n",
      "best_train_reward:0.846036788206\n"
     ]
    }
   ],
   "source": [
    "# Choose model with cross validation\n",
    "# Supervised Model: DT\n",
    "# Dataset: original\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "best_train_reward = 0\n",
    "for c in np.range(2, 10):\n",
    "    clf = DT(max_depth=4)\n",
    "    rewards = cross_validate(clf, x_train, y_train, cv=5, n_jobs=5, scoring=aucprc_scorer)\n",
    "    train_reward = np.array(rewards['train_score']).mean()\n",
    "    reward = np.array(rewards['test_score']).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_train_reward = train_reward\n",
    "        best_c = c\n",
    "print 'best_c:{}'.format(best_c)\n",
    "print 'best_reward:{}'.format(best_reward)\n",
    "print 'best_train_reward:{}'.format(best_train_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848909682323\n"
     ]
    }
   ],
   "source": [
    "# Test performance trianed on the original labeled dataset\n",
    "clf = DT(max_depth=4)\n",
    "clf.fit(x_train, y_train)\n",
    "preds = clf.predict_proba(x_train)[:, 1]\n",
    "print evaluate_auc_prc(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 284315, 1: 492})"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 196800, 1: 492})\n",
      "Counter({0: 201720, 1: 492})\n",
      "Counter({0: 206640, 1: 492})\n",
      "Counter({0: 211560, 1: 492})\n",
      "Counter({0: 216480, 1: 492})\n",
      "Counter({0: 221400, 1: 492})\n",
      "Counter({0: 226320, 1: 492})\n",
      "Counter({0: 231240, 1: 492})\n",
      "Counter({0: 236160, 1: 492})\n",
      "Counter({0: 241080, 1: 492})\n",
      "Counter({0: 246000, 1: 492})\n",
      "Counter({0: 250920, 1: 492})\n",
      "Counter({0: 255840, 1: 492})\n",
      "Counter({0: 260760, 1: 492})\n",
      "Counter({0: 265680, 1: 492})\n",
      "best_train_reward:0.85466396156\n",
      "best_i:490\n"
     ]
    }
   ],
   "source": [
    "# Choose under-sampling ratio for different under-sampling methods\n",
    "# Supervised Model: DT\n",
    "# Test under-sampling methods\n",
    "from imblearn.under_sampling import (NearMiss, RandomUnderSampler, EditedNearestNeighbours, \n",
    "                                     CondensedNearestNeighbour, ClusterCentroids, TomekLinks,\n",
    "                                     RepeatedEditedNearestNeighbours, AllKNN)\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "\n",
    "max_reward = 0\n",
    "max_i = 0\n",
    "rewards = []\n",
    "train_rewards = []\n",
    "train_x = x_train\n",
    "train_y = y_train\n",
    "\n",
    "best_train_reward = 0\n",
    "for i in np.arange(400, 550, 10):\n",
    "    print 'i:{}'.format(i)\n",
    "    pos_num = (train_y == 1).sum()\n",
    "    neg_num = (train_y == 0).sum()\n",
    "    sampler = RandomUnderSampler(ratio={0:i*pos_num})\n",
    "    train_x_s, train_y_s = sampler.fit_sample(train_x, train_y)\n",
    "    clf.fit(train_x_s, train_y_s)\n",
    "    preds = clf.predict_proba(train_x)[:, 1]\n",
    "    train_reward = evaluate_auc_prc(train_y, preds)\n",
    "    if best_train_reward < train_reward:\n",
    "        best_train_reward = train_reward    \n",
    "        max_i = i\n",
    "    print 'reward:{}'.format(reward)\n",
    "print 'best_train_reward:{}'.format(best_train_reward)\n",
    "print 'best_i:{}'.format(max_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828574718075\n",
      "0.838329125368\n",
      "0.836883933829\n",
      "0.836844033116\n",
      "0.840668879763\n",
      "0.835850127281\n",
      "0.849854031059\n",
      "0.830260229698\n",
      "0.835669272118\n",
      "0.839223193687\n",
      "0.83493110255\n",
      "0.835986754171\n",
      "0.83752225517\n",
      "0.835986754171\n",
      "0.834683331402\n",
      "best under-sampling ratio for EasyEnsemble:460\n",
      "best reward for EasyEnsemble:0.849854031059\n"
     ]
    }
   ],
   "source": [
    "# Perform EasyEnsemble and BalanceCascade\n",
    "from imblearn.ensemble import EasyEnsemble, BalanceCascade\n",
    "\n",
    "train_x = x_train\n",
    "train_y = y_train\n",
    "pos_num = (train_y == 1).sum()\n",
    "neg_num = (train_y == 0).sum()\n",
    "\n",
    "for sampler, name in zip([EasyEnsemble, BalanceCascade],\n",
    "                         ['EasyEnsemble']):\n",
    "    max_i = 1\n",
    "    best_reward = -1\n",
    "    for i in [490]:\n",
    "        sample = sampler(ratio={0:i*pos_num}, replacement=False, n_subsets=10)\n",
    "        train_x_s, train_y_s = sample.fit_sample(x_train, y_train)\n",
    "        preds = None\n",
    "        for x, y in zip(train_x_s, train_y_s):\n",
    "            clf.fit(x, y)\n",
    "            if preds is None:\n",
    "                preds = clf.predict(train_x)\n",
    "            else:\n",
    "                preds += clf.predict(train_x)\n",
    "        preds = (preds >= ((len(train_x_s)+1)/2)).astype('int32')\n",
    "        reward = evaluate_auc_prc(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward    \n",
    "            max_i = i\n",
    "        print(reward)\n",
    "    print 'best under-sampling ratio for {}:{}'.format(name, max_i)\n",
    "    print 'best reward for {}:{}'.format(name, best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best over-sampling ratio for RandomOverSampler:2\n",
      "best reward with RandomOverSampler:0.861420563959\n",
      "best over-sampling ratio for SMOTE:1\n",
      "best reward with SMOTE:0.848909682323\n",
      "best over-sampling ratio for ADASYN:1\n",
      "best reward with ADASYN:0.848909682323\n"
     ]
    }
   ],
   "source": [
    "# Choose over-sampling ratio for different orver-sampling methods\n",
    "# Supervised Model: DT(max_depth=4)\n",
    "# Over sampling methods: Random, SMOTE, ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "\n",
    "for sampler, name, time in zip([RandomOverSampler, SMOTE, ADASYN],\n",
    "                         ['RandomOverSampler', 'SMOTE', 'ADASYN'], [10, 10, 10]):\n",
    "    max_i = 1\n",
    "    best_reward = -1\n",
    "    for i in np.arange(1, 10, 1):\n",
    "        sample = sampler(ratio={1:int(i*pos_num)})\n",
    "        train_x_s, train_y_s = sample.fit_sample(train_x, train_y)\n",
    "        clf.fit(train_x_s, train_y_s)\n",
    "        preds = clf.predict_proba(train_x)[:, 1]\n",
    "        reward = evaluate_auc_prc(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward    \n",
    "            max_i = i\n",
    "    print 'best over-sampling ratio for {}:{}'.format(name, max_i)\n",
    "    best_reward = 0\n",
    "    bset_set = None\n",
    "    for i in np.arange(time):\n",
    "        sample = sampler(ratio={1:int(max_i*pos_num)})\n",
    "        train_x_s, train_y_s = sample.fit_sample(train_x, train_y)\n",
    "        clf.fit(train_x_s, train_y_s)\n",
    "        preds = clf.predict_proba(train_x)[:, 1]\n",
    "        reward = evaluate_auc_prc(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward   \n",
    "            bset_set = (train_x_s, train_y_s)\n",
    "    print 'best reward with {}:{}'.format(name, best_reward)\n",
    "    pickle.dump({'x':bset_set[0], 'y':np.eye(2)[bset_set[1].astype('int32')]}, open('../data/real/creditcard/train_{}.pkl'.format(name), 'wb+'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_s"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
