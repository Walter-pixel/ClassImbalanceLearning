{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0e236465-31d2-7cb7-e30c-534829e74e67"
   },
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "8dc9f4a5-a803-262d-0a35-ec5b91f72e43",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "81b672d5-0878-f7da-0df3-ee123232c67d"
   },
   "source": [
    "# 2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "add7a891-d611-71ac-3281-dfa60de1f2dc",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/real/spam.csv\",encoding='latin-1', header = 0, sep='\\t')\n",
    "data['Class'] = data.Class.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "6c93ebf5-0a0e-b9b6-6796-204c159ba70b",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "9847a57c-6fd9-2399-0cdf-bd4825784c50",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Count observations in each label\n",
    "print data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "x_train = data['Text'].values\n",
    "y_train = data['Class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b63d1a80-fd4f-1a28-f3bf-d81749997e65"
   },
   "source": [
    "# 4.Text Transformation\n",
    "Various text transformation techniques such as stop word removal, lowering the texts, tfidf transformations, prunning, stemming can be performed using sklearn.feature_extraction libraries. Then, the data can be convereted into bag-of-words. <br> <br>\n",
    "For this problem, Let us see how our model performs without removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ee2c40c7-3705-9c62-9053-f87334019640",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "vect = TfidfVectorizer()\n",
    "x_train = vect.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8749)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce data dimension\n",
    "x_train = TruncatedSVD(n_components=100).fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump({'x':x_train, 'y':np.eye(2)[y_train.astype('int32')]}, open('../data/real/spam/train.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e879d59e-df84-8de5-51f4-7bb2c01cba6c"
   },
   "source": [
    "# 6. Machine Learning models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leshare/softwares/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import LinearSVC as SVM\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.cross_validation import train_test_split # to split the data\n",
    "from sklearn.cross_validation import KFold # For cross vbalidation\n",
    "from sklearn.model_selection import GridSearchCV # for tunnig hyper parameter it will use all combination of given parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV # same for tunning hyper parameter but will use random combinations of parameters\n",
    "from sklearn.metrics import (confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report,\n",
    "                             accuracy_score,confusion_matrix,classification_report)\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, precision_recall_fscore_support\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "def evaluate_auc_prc(y, pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y, pred)\n",
    "    aucprc = auc(recall, precision)\n",
    "    #print 'AUPRC:{}'.format(aucprc)\n",
    "    #plt.title('Precision Recall Curve')\n",
    "    #plt.plot(precision, recall, 'b',label='AUC = %0.2f'% aucprc)\n",
    "    #plt.legend(loc='lower right')\n",
    "    #plt.ylabel('Precision')\n",
    "    #plt.xlabel('Recall')\n",
    "    #plt.show()\n",
    "    return aucprc\n",
    "\n",
    "\n",
    "def evaluate_f1(y, y_pred, pos_label=1):\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y, y_pred, pos_label=1)\n",
    "    print classification_report(y, y_pred)\n",
    "    return f1[1]\n",
    "\n",
    "def evaluate_f2(y, y_pred, pos_label=1):\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y, y_pred, pos_label=1)\n",
    "    #print classification_report(y, y_pred)\n",
    "    f2 = (1+0.5**2)*(precision[1]*recall[1])/(0.5**2*precision[1]+recall[1])\n",
    "   \n",
    "    return f2\n",
    "\n",
    "aucprc_score = make_scorer(evaluate_auc_prc, greater_is_better=True)\n",
    "\n",
    "gms = make_scorer(geometric_mean_score, greater_is_better=True)\n",
    "\n",
    "f1_scorer = make_scorer(evaluate_f1, greater_is_better=True)\n",
    "\n",
    "f2_scorer = make_scorer(evaluate_f2, greater_is_better=True)\n",
    "\n",
    "def data_split(x, test_size=0.4, seed=1): # preparing data for training and testing as we are going to use different data \n",
    "    #again and again so make a function\n",
    "    x_features= x.ix[:,x.columns != \"Class\"]\n",
    "    x_labels=x.ix[:,x.columns==\"Class\"]\n",
    "    x_features_train,x_features_test,x_labels_train,x_labels_test = train_test_split(x_features,x_labels,\n",
    "                                                                                     test_size=test_size, \n",
    "                                                                                     random_state=seed)\n",
    "    x_features_train.index = np.arange(len(x_features_train))\n",
    "    x_labels_train.index = np.arange(len(x_labels_train))\n",
    "    x_features_test.index = np.arange(len(x_features_test))\n",
    "    x_labels_test.index = np.arange(len(x_labels_test))\n",
    "    print(\"length of training data\")\n",
    "    print(len(x_features_train))\n",
    "    print(\"length of test data\")\n",
    "    print(len(x_features_test))\n",
    "    return(x_features_train,x_features_test,x_labels_train,x_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c for MLP:8\n",
      "best_reward MLP:0.93270938744\n"
     ]
    }
   ],
   "source": [
    "# Choose classifer with cross validation\n",
    "# Supervised Model: LR, SVM (linear), SVM (rbf), DT, KNN, MLP\n",
    "# Dataset: original\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# LR\n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]:\n",
    "#     clf = LR(C=c, random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=f2_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for LR:{}'.format(best_c)\n",
    "# print 'best_reward for LR:{}'.format(best_reward)\n",
    "\n",
    "# # SVM (linear)\n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]:\n",
    "#     clf = SVM(C=c, random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=f2_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for SVM:{}'.format(best_c)\n",
    "# print 'best_reward for SVM:{}'.format(best_reward)\n",
    "\n",
    "# # SVM (rbf)\n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]:\n",
    "#     clf = SVC(C=c, kernel='rbf', random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=f2_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for SVC:{}'.format(best_c)\n",
    "# print 'best_reward for SVC:{}'.format(best_reward)\n",
    "\n",
    "# # DT \n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "#     clf = DT(max_depth=c, random_state=0)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=f2_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for DT:{}'.format(best_c)\n",
    "# print 'best_reward DT:{}'.format(best_reward)\n",
    "\n",
    "# # KNN \n",
    "# best_c = 0\n",
    "# best_reward = 0\n",
    "# for c in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "#     clf = KNN(n_neighbors=c)\n",
    "#     reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=f2_scorer)).mean()\n",
    "#     if reward > best_reward:\n",
    "#         best_reward = reward\n",
    "#         best_c = c\n",
    "# print 'best_c for KNN:{}'.format(best_c)\n",
    "# print 'best_reward KNN:{}'.format(best_reward)\n",
    "\n",
    "# MLP \n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "    clf = MLP(hidden_layer_sizes=[c], random_state=0)\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, scoring=f2_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c for MLP:{}'.format(best_c)\n",
    "print 'best_reward MLP:{}'.format(best_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f9074dc-58bb-e988-4e73-a08acf80f37e"
   },
   "source": [
    "###  Multinomial Naive Bayes\n",
    "Generally, Naive Bayes works well on text data. Multinomail Naive bayes is best suited for classification with discrete features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:100.0\n",
      "best_c:0\n",
      "best_reward for NB:0\n"
     ]
    }
   ],
   "source": [
    "# Choose hyper-parameters with cross validation\n",
    "# Supervised Model: NB\n",
    "# Dataset: original\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in [1e2]:\n",
    "    print('c:{}'.format(c))\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_train)\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=2, n_jobs=2, \n",
    "                                      scoring=f2_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c:{}'.format(best_c)\n",
    "print 'best_reward for NB:{}'.format(best_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d149acba-bd73-7ed3-f121-ab8c113401b5"
   },
   "source": [
    "###  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "_cell_guid": "e0111bd9-eda4-790a-9bf7-a47b0ce80804",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c:10.0\n",
      "best_reward for LR:0.930359664121\n"
     ]
    }
   ],
   "source": [
    "# Choose hyper-parameters with cross validation\n",
    "# Supervised Model: LR\n",
    "# Dataset: original\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]:\n",
    "    clf = LR(C=c, random_state=0)\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, \n",
    "                                      scoring=f2_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c:{}'.format(best_c)\n",
    "print 'best_reward for LR:{}'.format(best_reward)\n",
    "clf = LR(C=best_c, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935938877461\n"
     ]
    }
   ],
   "source": [
    "clf =LR(C=1e1, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "preds = clf.predict(x_train)\n",
    "print evaluate_f2(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d149acba-bd73-7ed3-f121-ab8c113401b5"
   },
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "_cell_guid": "e0111bd9-eda4-790a-9bf7-a47b0ce80804",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c:1000.0\n",
      "best_reward for linear SVM:0.92530228667\n"
     ]
    }
   ],
   "source": [
    "# Choose hyper-parameters with cross validation\n",
    "# Supervised Model: LR\n",
    "# Dataset: original\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in [1e1, 1e2, 1e3]:\n",
    "    clf = SVM(C=c, random_state=0)\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, \n",
    "                                      scoring=f2_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c:{}'.format(best_c)\n",
    "print 'best_reward for linear SVM:{}'.format(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939892259711\n"
     ]
    }
   ],
   "source": [
    "clf = SVM(C=1e1, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "preds = clf.predict(x_train)\n",
    "print evaluate_f2(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d14463a-65b4-c019-82b8-d055a942feef"
   },
   "source": [
    "###  $k$-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "_cell_guid": "e0111bd9-eda4-790a-9bf7-a47b0ce80804",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c:6\n",
      "best_reward for KNN:0.922153122758\n"
     ]
    }
   ],
   "source": [
    "# Choose model with cross validation\n",
    "# Supervised Model: KNN\n",
    "# Dataset: original\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in np.arange(3,10):\n",
    "    clf = KNN(n_neighbors=c)\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, \n",
    "                                      scoring=f2_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c:{}'.format(best_c)\n",
    "print 'best_reward for KNN:{}'.format(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947978690066\n"
     ]
    }
   ],
   "source": [
    "clf = KNN(n_neighbors=6)\n",
    "clf.fit(x_train, y_train)\n",
    "preds = clf.predict(x_train)\n",
    "print evaluate_f2(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "507f25c8-331c-b20e-e8a1-502681b2367a"
   },
   "source": [
    "###  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "_cell_guid": "e0111bd9-eda4-790a-9bf7-a47b0ce80804",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c:6\n",
      "best_reward for DT:0.839226818602\n"
     ]
    }
   ],
   "source": [
    "# Choose model with cross validation\n",
    "# Supervised Model: DT\n",
    "# Dataset: original\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in np.arange(2, 20):\n",
    "    clf = DT(max_depth=c)\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, \n",
    "                                      scoring=f2_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c:{}'.format(best_c)\n",
    "print 'best_reward for DT:{}'.format(best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936002255427\n"
     ]
    }
   ],
   "source": [
    "clf = DT(max_depth=6)\n",
    "clf.fit(x_train, y_train)\n",
    "preds = clf.predict(x_train)\n",
    "print evaluate_f2(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "507f25c8-331c-b20e-e8a1-502681b2367a"
   },
   "source": [
    "###  AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c:1\n",
      "best_reward for AdaBoost:0.902406624162\n"
     ]
    }
   ],
   "source": [
    "# Choose model with cross validation\n",
    "# Supervised Model: AdaBoost\n",
    "# Dataset: original\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_c = 0\n",
    "best_reward = 0\n",
    "for c in np.arange(1, 2):\n",
    "    clf = AdaBoostClassifier()\n",
    "    reward = np.array(cross_val_score(clf, x_train, y_train, cv=5, n_jobs=5, \n",
    "                                      scoring=f2_scorer)).mean()\n",
    "    if reward > best_reward:\n",
    "        best_reward = reward\n",
    "        best_c = c\n",
    "print 'best_c:{}'.format(best_c)\n",
    "print 'best_reward for AdaBoost:{}'.format(best_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7ed75f56-aa3b-0bf0-76e7-1eaea1cc1e6a"
   },
   "source": [
    "# Sampling Evaluation with LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Performance on original dataset with the chosen model.\n",
    "clf = LR(C=1e1, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "preds = clf.predict(x_train)\n",
    "print evaluate_f2(y_train, preds)\n",
    "# print 'reward on original dataset:{}'.format(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best under-sampling ratio with Cluster:6.0\n",
      "best reward:0.931982633864\n",
      "best reward with Cluster:0.931982633864\n",
      "best under-sampling ratio with TomekLinks:6.0\n",
      "best reward:0.935938877461\n",
      "best reward with TomekLinks:0.935938877461\n",
      "best under-sampling ratio with ALLKNN:6.0\n",
      "best reward:0.933485583785\n",
      "best reward with ALLKNN:0.933485583785\n"
     ]
    }
   ],
   "source": [
    "# Choose under-sampling ratio for different under-sampling methods\n",
    "# Supervised Model: SVM(C=1e2, kernel='rbf', random_state=0)\n",
    "# Under sampling methods: Random, ENN, Cluster, TomekLinks, ALLKNN\n",
    "from imblearn.under_sampling import (NearMiss, RandomUnderSampler, EditedNearestNeighbours, \n",
    "                                     CondensedNearestNeighbour, ClusterCentroids, TomekLinks,\n",
    "                                     RepeatedEditedNearestNeighbours, AllKNN)\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "train_x = x_train\n",
    "train_y = y_train\n",
    "pos_num = (train_y == 1).sum()\n",
    "neg_num = (train_y == 0).sum()\n",
    "\n",
    "for sampler, name, time in zip([RandomUnderSampler, EditedNearestNeighbours, ClusterCentroids, TomekLinks, AllKNN],\n",
    "                         ['Random', 'ENN', 'Cluster', 'TomekLinks', 'ALLKNN'], [50, 1, 1, 1, 1]):\n",
    "    max_i = 1\n",
    "    best_reward = -1\n",
    "    for i in np.arange(1, 1.0*neg_num/pos_num, 0.5):\n",
    "        sample = sampler(ratio={0:int(i*pos_num)})\n",
    "        train_x_s, train_y_s = sample.fit_sample(train_x, train_y)\n",
    "        clf.fit(train_x_s, train_y_s)\n",
    "        preds = clf.predict(train_x)\n",
    "        reward = evaluate_f2(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward    \n",
    "            max_i = i\n",
    "    print 'best under-sampling ratio with {}:{}'.format(name, max_i)\n",
    "    \n",
    "    best_reward = 0\n",
    "    for i in np.arange(time):\n",
    "        sample = sampler(ratio={0:int(max_i*pos_num)})\n",
    "        train_x_s, train_y_s = sample.fit_sample(train_x, train_y)\n",
    "        clf.fit(train_x_s, train_y_s)\n",
    "        preds = clf.predict(train_x)\n",
    "        reward = evaluate_f2(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward    \n",
    "    print 'best reward with {}:{}'.format(name, best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best under-sampling ratio for EasyEnsemble:6.2\n",
      "best reward for EasyEnsemble:0.938864628821\n"
     ]
    }
   ],
   "source": [
    "# Perform EasyEnsemble and BalanceCascade\n",
    "from imblearn.ensemble import EasyEnsemble, BalanceCascade\n",
    "\n",
    "train_x = x_train\n",
    "train_y = y_train\n",
    "pos_num = (train_y == 1).sum()\n",
    "neg_num = (train_y == 0).sum()\n",
    "\n",
    "for sampler, name in zip([EasyEnsemble, BalanceCascade],\n",
    "                         ['EasyEnsemble']):\n",
    "    max_i = 1\n",
    "    best_reward = -1\n",
    "    for i in np.arange(1, 1.0*neg_num/pos_num, 0.2):\n",
    "        sample = sampler(ratio={0:int(i*pos_num)}, replacement=False, n_subsets=10)\n",
    "        train_x_s, train_y_s = sample.fit_sample(x_train, y_train)\n",
    "        preds = None\n",
    "        for x, y in zip(train_x_s, train_y_s):\n",
    "            clf.fit(x, y)\n",
    "            if preds is None:\n",
    "                preds = clf.predict(train_x)\n",
    "            else:\n",
    "                preds += clf.predict(train_x)\n",
    "        preds = (preds >= ((len(train_x_s)+1)/2)).astype('int32')\n",
    "        reward = evaluate_f2(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward    \n",
    "            max_i = i\n",
    "    print 'best under-sampling ratio for {}:{}'.format(name, max_i)\n",
    "    print 'best reward for {}:{}'.format(name, best_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best over-sampling ratio for RandomOverSampler:1.0\n",
      "best reward with RandomOverSampler:0.935938877461\n",
      "best over-sampling ratio for SMOTE:1.0\n",
      "best reward with SMOTE:0.935938877461\n",
      "best over-sampling ratio for ADASYN:1.0\n",
      "best reward with ADASYN:0.935938877461\n"
     ]
    }
   ],
   "source": [
    "# Choose over-sampling ratio for different orver-sampling methods\n",
    "# Supervised Model: DT(max_depth=4)\n",
    "# Over sampling methods: Random, SMOTE, ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "\n",
    "for sampler, name, time in zip([RandomOverSampler, SMOTE, ADASYN],\n",
    "                         ['RandomOverSampler', 'SMOTE', 'ADASYN'], [10, 10, 10]):\n",
    "    max_i = 1\n",
    "    best_reward = -1\n",
    "    for i in np.arange(1, 6, 0.2):\n",
    "        sample = sampler(ratio={1:int(i*pos_num)})\n",
    "        train_x_s, train_y_s = sample.fit_sample(train_x, train_y)\n",
    "        clf.fit(train_x_s, train_y_s)\n",
    "        preds = clf.predict(train_x)\n",
    "        reward = evaluate_f2(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward    \n",
    "            max_i = i\n",
    "    print 'best over-sampling ratio for {}:{}'.format(name, max_i)\n",
    "    best_reward = 0\n",
    "    bset_set = None\n",
    "    for i in np.arange(time):\n",
    "        sample = sampler(ratio={1:int(max_i*pos_num)})\n",
    "        train_x_s, train_y_s = sample.fit_sample(train_x, train_y)\n",
    "        clf.fit(train_x_s, train_y_s)\n",
    "        preds = clf.predict(train_x)\n",
    "        reward = evaluate_f2(train_y, preds)\n",
    "        if best_reward < reward:\n",
    "            best_reward = reward   \n",
    "            bset_set = (train_x_s, train_y_s)\n",
    "    print 'best reward with {}:{}'.format(name, best_reward)\n",
    "    pickle.dump({'x':bset_set[0], 'y':np.eye(2)[bset_set[1].astype('int32')]}, open('../data/real/spam/train_{}.pkl'.format(name), 'wb+'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_num"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
